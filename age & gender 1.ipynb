{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5542,
     "status": "ok",
     "timestamp": 1743839000425,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "8gdm0WqKniDV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31829,
     "status": "ok",
     "timestamp": 1743839038899,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "bI16f4Z1lb5s",
    "outputId": "6245b34e-a688-4652-c2c4-bea82e9525e4"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive')\n",
    "\n",
    "# Assuming your zip file is named \"archive.zip\" in your Google Drive\n",
    "# Adjust the path to match where your file is located\n",
    "zip_path = \"/content/drive/MyDrive/datasets/archive.zip\"  # Change this to your actual file path\n",
    "\n",
    "# Create a directory to extract to\n",
    "!mkdir -p \"/content/UTKFace_extracted\"\n",
    "\n",
    "# Extract the zip file\n",
    "!unzip -q \"{zip_path}\" -d \"/content/UTKFace_extracted\"\n",
    "\n",
    "# Check what was extracted\n",
    "!ls \"/content/UTKFace_extracted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1743839042414,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "zDghpiHaseT8",
    "outputId": "9f877a7e-53e4-4395-efeb-466b7d102a06"
   },
   "outputs": [],
   "source": [
    "# Update this to point to the correct folder containing the images\n",
    "# The exact path depends on how the files are organized in the zip\n",
    "dataset_path = \"/content/UTKFace_extracted\"  # You might need to add subdirectories\n",
    "\n",
    "# If the images are in a subdirectory, check the structure\n",
    "import os\n",
    "print(os.listdir(dataset_path))\n",
    "\n",
    "# Update path if needed, e.g., if images are in a subfolder\n",
    "# dataset_path = \"/content/UTKFace_extracted/UTKFace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1743839045953,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "3H6vek65l__h"
   },
   "outputs": [],
   "source": [
    "dataset_path = \"UTKFace_extracted\"  # Update if necessary\n",
    "image_size = 64\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1743839054829,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "R9QZesbAq_qY",
    "outputId": "73dee309-e81b-431c-918d-7ae260cf4b29"
   },
   "outputs": [],
   "source": [
    "def find_image_directory(base_path):\n",
    "    for root, dirs, files in os.walk(base_path):\n",
    "        jpg_count = len([f for f in files if f.lower().endswith('.jpg')])\n",
    "        png_count = len([f for f in files if f.lower().endswith('.png')])\n",
    "        if jpg_count > 0 or png_count > 0:\n",
    "            print(f\"Found {jpg_count + png_count} images in {root}\")\n",
    "            return root\n",
    "    return base_path\n",
    "\n",
    "# Try to automatically find the directory with images\n",
    "dataset_path = find_image_directory(dataset_path)\n",
    "print(f\"Using dataset path: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4183,
     "status": "ok",
     "timestamp": 1743839063151,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "WJTad2eRutVq",
    "outputId": "1b18b8ed-6726-4761-ec8a-f302f216b238"
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_dataset(dataset_path):\n",
    "    images = []\n",
    "    ages = []\n",
    "    genders = []\n",
    "\n",
    "    print(f\"Looking for images in: {dataset_path}\")\n",
    "    file_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "    # For each image in the dataset\n",
    "    for filename in os.listdir(dataset_path):\n",
    "        file_count += 1\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            try:\n",
    "                # Extract age and gender from filename\n",
    "                # UTKFace filename format: [age]_[gender]_[race]_[date&time].jpg\n",
    "                parts = filename.split('_')\n",
    "                age = int(parts[0])\n",
    "                gender = int(parts[1])  # 0 for male, 1 for female\n",
    "\n",
    "                # Load and preprocess image\n",
    "                img_path = os.path.join(dataset_path, filename)\n",
    "                img = cv2.imread(img_path)\n",
    "                if img is None:\n",
    "                    error_count += 1\n",
    "                    if error_count <= 5:\n",
    "                        print(f\"Could not read image: {img_path}\")\n",
    "                    continue\n",
    "\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "                img = cv2.resize(img, (image_size, image_size))  # Resize\n",
    "                img = img / 255.0  # Normalize\n",
    "\n",
    "                # Append to lists\n",
    "                images.append(img)\n",
    "                ages.append(age)\n",
    "                genders.append(gender)\n",
    "\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                if error_count <= 5:  # Only print first few errors\n",
    "                    print(f\"Error processing {filename}: {e}\")\n",
    "                continue\n",
    "\n",
    "    print(f\"Processed {file_count} files, encountered {error_count} errors, loaded {len(images)} valid images\")\n",
    "    return np.array(images), np.array(ages), np.array(genders)\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading dataset...\")\n",
    "images, ages, genders = load_dataset(dataset_path)\n",
    "print(f\"Dataset loaded: {len(images)} images\")\n",
    "\n",
    "# Verify we have enough images\n",
    "if len(images) == 0:\n",
    "    raise ValueError(\"No valid images were loaded. Please check the dataset path and file format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 987,
     "status": "ok",
     "timestamp": 1743839071431,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "NpS-XDkNu-DZ",
    "outputId": "31ef8dde-c219-47b6-d4c5-c37bf991c9b5"
   },
   "outputs": [],
   "source": [
    "# Quick visualization of some sample images\n",
    "def visualize_samples(images, ages, genders, num_samples=5):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    indices = np.random.choice(range(len(images)), num_samples, replace=False)\n",
    "\n",
    "    for i, idx in enumerate(indices):\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(images[idx])\n",
    "        gender_label = \"Female\" if genders[idx] == 1 else \"Male\"\n",
    "        plt.title(f\"Age: {ages[idx]}, Gender: {gender_label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize a few samples\n",
    "if len(images) > 0:\n",
    "    visualize_samples(images, ages, genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1743839078826,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "K58IagoYvIIU",
    "outputId": "09e5fd6d-2c27-450b-b0c1-7ad93d4430bb"
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, age_train, age_test, gender_train, gender_test = train_test_split(\n",
    "    images, ages, genders, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {len(X_train)} images\")\n",
    "print(f\"Testing set: {len(X_test)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 435,
     "status": "ok",
     "timestamp": 1743839083993,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "uhhojHBmvQxG"
   },
   "outputs": [],
   "source": [
    "# Data augmentation for training set\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 705
    },
    "executionInfo": {
     "elapsed": 3519,
     "status": "ok",
     "timestamp": 1743839093217,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "Yjpm64eEvlPs",
    "outputId": "7f3bf29c-b864-4d11-d6dd-026410ade3d5"
   },
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "def build_model(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Convolutional layers\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Flatten the output\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    # Output layers\n",
    "    age_output = Dense(1, name='age_output')(x)  # Regression task\n",
    "    gender_output = Dense(1, activation='sigmoid', name='gender_output')(x)  # Binary classification\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=[age_output, gender_output])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "              loss={'age_output': 'mse', 'gender_output': 'binary_crossentropy'},\n",
    "              metrics={'age_output': 'mae', 'gender_output': 'accuracy'})\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = build_model((image_size, image_size, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 138519,
     "status": "ok",
     "timestamp": 1743839335742,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "Q-7iRzkmy9Hq",
    "outputId": "a0a897b7-6571-4f8c-c2ef-71ce1c06c722"
   },
   "outputs": [],
   "source": [
    "def multi_output_generator(X, y_age, y_gender, batch_size=32):\n",
    "    while True:\n",
    "        # Get random batch indices\n",
    "        idx = np.random.randint(0, X.shape[0], batch_size)\n",
    "\n",
    "        # Get batch data\n",
    "        batch_X = X[idx]\n",
    "        batch_age = y_age[idx]\n",
    "        batch_gender = y_gender[idx]\n",
    "\n",
    "        # Apply augmentation to images (optional)\n",
    "        # This is a simplified version - you'd need to implement actual augmentation\n",
    "\n",
    "        yield batch_X, {'age_output': batch_age, 'gender_output': batch_gender}\n",
    "\n",
    "# Then use it in your model.fit:\n",
    "history = model.fit(\n",
    "    multi_output_generator(X_train, age_train, gender_train, batch_size),\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=(X_test, {'age_output': age_test, 'gender_output': gender_test}),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1304,
     "status": "ok",
     "timestamp": 1743839574900,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "kBy2coyjv46G",
    "outputId": "46056c8b-7812-42ca-a909-098d1c49f8a8"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "evaluation = model.evaluate(X_test, {'age_output': age_test, 'gender_output': gender_test})\n",
    "print(f\"Test Loss: {evaluation[0]}\")\n",
    "print(f\"Age MAE: {evaluation[1]}\")\n",
    "print(f\"Gender Accuracy: {evaluation[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 458,
     "status": "ok",
     "timestamp": 1743839884933,
     "user": {
      "displayName": "ANSH PRADHAN",
      "userId": "14887704716635941699"
     },
     "user_tz": -330
    },
    "id": "9uj_0Myk8j-w"
   },
   "outputs": [],
   "source": [
    "# Function to make predictions on new images\n",
    "def predict_age_gender(image_path, model):\n",
    "    # Load and preprocess the image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (image_size, image_size))\n",
    "    img = img / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    # Make prediction\n",
    "    age_pred, gender_pred = model.predict(img)\n",
    "\n",
    "    # Process predictions\n",
    "    age = int(age_pred[0][0])\n",
    "    gender = \"Female\" if gender_pred[0][0] > 0.5 else \"Male\"\n",
    "\n",
    "    return age, gender, img[0]  # Return preprocessed image for display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H84qiv3h9qKM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPdSJ1COBqlAUNYey3FU6jH",
   "gpuType": "T4",
   "mount_file_id": "13PnRc_J0QMeLO8WX_-a90Yje4pYUYLd7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
